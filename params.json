{"name":"Distributed-prime-sieve","tagline":"Distributed prime sieve in heterogeneous computer clusters","body":"# [Distributed prime sieve](https://github.com/carlosmccosta/Distributed-Prime-Sieve)\r\n\r\n## Overview\r\n***\r\nThis project provides several efficient implementations of ditributed prime sieves and has the following associated paper:\r\n\r\n[Distributed prime sieve in heterogeneous computer clusters](https://www.researchgate.net/publication/257213711_Distributed_prime_sieve_in_heterogeneous_computer_clusters)\r\n\r\n\r\n**Abstract:**\r\nPrime numbers play a pivotal role in current encryption algorithms  and given the rise of \r\ncloud computing, the need for larger primes never been so high. This increase in available computation \r\npower can be used to either try to break the encryption or to strength it by finding larger primes. With \r\nthis in mind, this paper provides an analysis of different sieves  implementations that can be used  to \r\ngenerate primes up to 2^64. It starts by analyzing cache friendly sequential sieves with wheel factorization, then expands to multicore architectures and ends with a cache friendly segmented hybrid implementation of a distributed prime sieve, designed to  efficiently use all the available computation resources of  heterogeneous computer clusters with variable workload  and to scale very well to any cluster \r\nsize.\r\n\r\n\r\n\r\n## Results\r\n***\r\n![Fig. 1 - Global performance comparison](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/GlobalPerformance.png)\r\nFig. 1 - Global performance comparison\r\n\r\n\r\n![Fig. 2 - Real speedup](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/RealSpeedup.png)\r\nFig. 2 - Real speedup\r\n\r\n\r\n![Fig. 3 - Efficiency](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/Efficiency.png)\r\nFig. 3 - Efficiency\r\n\r\n\r\n![Fig. 4 - Scalability_shared_memory_algorithm_efficiency](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/Scalability_shared_memory_algorithm_efficiency.png)\r\nFig. 4 - Scalability of shared memory algorithm (efficiency vs number of cores)\r\n\r\n\r\n![Fig. 5 - Scalability_shared_memory_algorithm_time](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/Scalability_shared_memory_algorithm_time.png)\r\nFig. 5 - Scalability shared memory algorithm (running time vs number of cores)\r\n\r\n\r\n![Fig. 6 - Scalability_distributed_algorithm_efficiency](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/Scalability_distributed_algorithm_efficiency.png)\r\nFig. 6 - Scalability distributed algorithm (efficiency vs number of nodes - each node is a quadcore processor with different processing capabilities)\r\n\r\n\r\n![Fig. 7 - Scalability_distributed_algorithm_time](https://raw.github.com/carlosmccosta/Distributed-Prime-Sieve/master/DistributedPrimeSieve/docs/Scalability_shared_memory_algorithm_time.png)\r\nFig. 7 - Scalability distributed algorithm (running time vs number of nodes - each node is a quadcore processor with different processing capabilities)\r\n\r\n\r\n## Usage\r\n***\r\nA brief usage guide is available [here](https://github.com/carlosmccosta/Distributed-Prime-Sieve/blob/master/DistributedPrimeSieve/docs/usage.txt)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}